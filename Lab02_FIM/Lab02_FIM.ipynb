{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DSYvP0n8RjYH"
   },
   "source": [
    "# Lab02: Frequent itemset mining\n",
    "\n",
    "- Student ID: 20120547\n",
    "- Student name: V√µ Th√†nh Phong\n",
    "\n",
    "**How to do your homework**\n",
    "\n",
    "\n",
    "You will work directly on this notebook; the word `TODO` indicate the parts you need to do.\n",
    "\n",
    "You can discuss ideas with classmates as well as finding information from the internet, book, etc...; but *this homework must be your*.\n",
    "\n",
    "**How to submit your homework**\n",
    "\n",
    "Before submitting, rerun the notebook (`Kernel` ->` Restart & Run All`).\n",
    "\n",
    "Then create a folder named `ID` (for example, if your ID is 1234567, then name the folder `1234567`) Copy file notebook to this folder, compress and submit it on moodle.\n",
    "\n",
    "**Contents:**\n",
    "\n",
    "- Frequent itemset mining."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aXZ5gCVaRjYa"
   },
   "source": [
    "# 1. Preliminaries\n",
    "## This is how it all started ...\n",
    "- Rakesh Agrawal, Tomasz Imielinski, Arun N. Swami: Mining Association Rules between Sets of Items in Large Databases. SIGMOD Conference 1993: 207-216\n",
    "- Rakesh Agrawal, Ramakrishnan Srikant: Fast Algorithms for Mining Association Rules in Large Databases. VLDB 1994: 487-499\n",
    "\n",
    "**These two papers are credited with the birth of Data Mining**\n",
    "## Frequent itemset mining (FIM)\n",
    "\n",
    "Find combinations of items (itemsets) that occur frequently.\n",
    "## Applications\n",
    "- Items = products, transactions = sets of products someone bought in one trip to the store.\n",
    "$\\Rightarrow$ items people frequently buy together.\n",
    "    + Example: if people usually buy bread and coffee together, we run a sale of bread to attract people attention and raise price of coffee.\n",
    "- Items = webpages, transactions = words. Unusual words appearing together in a large number of documents, e.g., ‚ÄúBrad‚Äù and ‚ÄúAngelina,‚Äù may indicate an interesting relationship.\n",
    "- Transactions = Sentences, Items = Documents containing those sentences. Items that appear together too often could represent plagiarism."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x8vAJ8A2RjYi"
   },
   "source": [
    "## Transactional Database\n",
    "A transactional database $D$ consists of $N$ transactions: $D=\\left\\{T_1,T_2,...,T_N\\right\\}$. A transaction $T_n \\in D (1 \\le n \\le N)$ contains one or more items and that $I= \\left\\{ i_1,i_2,‚Ä¶,i_M \\right\\}$ is the set of distinct items in $D$, $T_n \\subset I$. Commonly, a transactional database is represented by a flat file instead of a database system: items are non-negative integers, each row represents a transaction, items in a transaction separated by space.\n",
    "\n",
    "Example: \n",
    "\n",
    "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 \n",
    "\n",
    "30 31 32 \n",
    "\n",
    "33 34 35 \n",
    "\n",
    "36 37 38 39 40 41 42 43 44 45 46 \n",
    "\n",
    "38 39 47 48 \n",
    "\n",
    "38 39 48 49 50 51 52 53 54 55 56 57 58 \n",
    "\n",
    "32 41 59 60 61 62 \n",
    "\n",
    "3 39 48 \n",
    "\n",
    "63 64 65 66 67 68 \n",
    "\n",
    "\n",
    "\n",
    "# Definition\n",
    "\n",
    "- Itemset: A collection of one or more items.\n",
    "    + Example: {1 4 5}\n",
    "- **k-itemset**: An itemset that contains k items.\n",
    "- Support: Frequency of occurrence of an itemset.\n",
    "    + Example: From the example above, item 3 appear in 2 transactions so its support is 2.\n",
    "- Frequent itemset: An itemset whose support is greater than or equal to a `minsup` threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hdykKxr6RjY-"
   },
   "source": [
    "# The Apriori Principle\n",
    "- If an itemset is frequent, then all of its subsets must also be frequent.\n",
    "- If an itemset is not frequent, then all of its supersets cannot be frequent.\n",
    "- The support of an itemset never exceeds the support of its subsets.\n",
    "$$ \\forall{X,Y}: (X \\subseteq Y) \\Rightarrow s(X)\\ge s(Y)$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NvfMR7-CRjZB"
   },
   "source": [
    "# 2. Implementation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p9gZh4DORjZD"
   },
   "source": [
    "## The Apriori algorithm\n",
    "Suppose:\n",
    "\n",
    "$C_k$ candidate itemsets of size k.\n",
    "\n",
    "$L_k$ frequent itemsets of size k.\n",
    "\n",
    "The level-wise approach of Apriori algorithm can be descibed as follow:\n",
    "1. k=1, $C_k$ = all items.\n",
    "2. While $C_k$ not empty:\n",
    "    3. Scan the database to find which itemsets in $C_k$ are frequent and put them into $L_k$.\n",
    "    4. Use $L_k$ to generate a collection of candidate itemsets $C_{k+1}$ of size k+1.\n",
    "    5. k=k+1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qF9xHOBLRjZJ"
   },
   "source": [
    "### Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "7F0lUOSuRjZN"
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1OogwdcLRjZf"
   },
   "source": [
    "### Read data\n",
    "First we have to read data from database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "U2bsGrTERjZg"
   },
   "outputs": [],
   "source": [
    "\n",
    "def readData(path):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    --------------------------\n",
    "        path: path of database D.\n",
    "         \n",
    "    --------------------------\n",
    "    Returns\n",
    "        data: a dictionary for representing database D\n",
    "                 - keys: transaction tids\n",
    "                 - values: itemsets.\n",
    "        s: support of distict items in D.\n",
    "    \"\"\"\n",
    "    data={}\n",
    "    s=defaultdict(lambda: 0) # Initialize a dictionary for storing support of items in I.  \n",
    "    with open(path,'rt') as f:\n",
    "        tid=1;\n",
    "        for line in f:\n",
    "            itemset=set(map(int,line.split())) # a python set is a native way for storing an itemset.\n",
    "            for item in itemset:  \n",
    "                s[item]+=1     #Why don't we compute support of items while reading data?\n",
    "            data[tid]= itemset\n",
    "            tid+=1\n",
    "    \n",
    "    return data, s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oSTC78WURjZu"
   },
   "source": [
    "### Tree Projection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uGAkmuXtRjZw"
   },
   "source": [
    "**I gave you pseudo code of Apriori algorithm above but we implement Tree Projection. Tell me the differences of two algorithms.**\n",
    "\n",
    "\n",
    "**TODO:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "BVRT5BnWRjZz"
   },
   "outputs": [],
   "source": [
    "def joinset(a, b):\n",
    "    '''\n",
    "    Parameters\n",
    "    -------------------\n",
    "        2 itemsets a and b (of course they are at same branch in search space)\n",
    "\n",
    "    -------------------\n",
    "    return\n",
    "        ret: itemset generated by joining a and b\n",
    "    '''\n",
    "    # TODO (hint: this function will be called in generateSearchSpace method.):\n",
    "    ret=list(set(a) | set(b))\n",
    "    return ret\n",
    "\n",
    "class TP:\n",
    "    def __init__(self, data=None, s=None, minSup=None):\n",
    "        self.data = data\n",
    "        self.s = {}\n",
    "\n",
    "        for key, support in sorted(s.items(), key=lambda item: item[1]):\n",
    "            self.s[key] = support\n",
    "        # TODO: why should we do this, answer it at the markdown below?\n",
    "\n",
    "        self.minSup = minSup\n",
    "        self.L = {}  # Store frequent itemsets mined from database\n",
    "        self.runAlgorithm()\n",
    "\n",
    "    def initialize(self):\n",
    "        \"\"\"\n",
    "        Initialize search space at first step\n",
    "        --------------------------------------\n",
    "        We represent our search space in a tree structure\n",
    "        \"\"\"\n",
    "        tree = {}\n",
    "\n",
    "        search_space = {}\n",
    "        for item, support in self.s.items():\n",
    "            search_space[item] = {}\n",
    "\n",
    "            search_space[item]['itemset'] = [item]\n",
    "            ''' \n",
    "            python set does not remain elements order\n",
    "            so we use a list to extend it easily when create new itemset \n",
    "            but why we store itemset in data by a python set???? '''\n",
    "            # TODO: study about python set and its advantages,\n",
    "            # answer at the markdown below.\n",
    "\n",
    "            search_space[item]['pruned'] = False\n",
    "            # TODO:\n",
    "            # After finish implementing the algorithm tell me why should you use this\n",
    "            # instead of delete item directly from search_space and tree.\n",
    "\n",
    "            search_space[item]['support'] = support\n",
    "\n",
    "            tree[item] = {}\n",
    "            '''\n",
    "            Why should i store an additional tree (here it called tree)? \n",
    "            Answer: This really help in next steps.\n",
    "\n",
    "            Remember that there is always a big gap from theory to practicality\n",
    "            and implementing this algorithm in python is not as simple as you think.\n",
    "            '''\n",
    "\n",
    "        return tree, search_space\n",
    "\n",
    "    def computeItemsetSupport(self, itemset):\n",
    "\n",
    "        '''Return support of itemset'''\n",
    "        # TODO (hint: this is why i use python set in data)\n",
    "        support=0\n",
    "        for i in self.data.keys():\n",
    "            if len(set(itemset)) == len(set(itemset).intersection(self.data[i])):\n",
    "                support+=1\n",
    "        return support/len(list(self.data.keys()))\n",
    "\n",
    "    def get_sub_tree(self, k, tree, search_space, itter_node):\n",
    "        if k == 0:\n",
    "            return search_space[itter_node]['support']\n",
    "        subtree = search_space[itter_node]\n",
    "        for node in subtree.keys():\n",
    "            k-=1\n",
    "            self.get_sub_tree(k,tree,search_space,node)\n",
    "\n",
    "\n",
    "    def prune(self, k, tree, search_space):\n",
    "\n",
    "        '''\n",
    "        In this method we will find out which itemset in current search space is frequent\n",
    "        itemset then add it to L[k]. In addition, we prune those are not frequent itemsets.\n",
    "        '''\n",
    "        if self.L.get(k) is None: self.L[k] = []\n",
    "        # TODO\n",
    "        if k==1:\n",
    "            minSup=self.minSup\n",
    "        elif k>1:\n",
    "            minSup=self.minSup/len(list(self.data.keys()))\n",
    "        for i in search_space.keys():\n",
    "            if search_space[i]['support']>=minSup:\n",
    "                self.L[k].append(search_space[i]['itemset'])\n",
    "            else:\n",
    "                search_space[i]['pruned']=True\n",
    "        if self.L[k]==[]:\n",
    "            del self.L[k]\n",
    "\n",
    "\n",
    "    def generateSearchSpace(self, k, tree, search_space):\n",
    "        '''\n",
    "        Generate search space for exploring k+1 itemset. (Recursive function)\n",
    "        '''\n",
    "        items = list(tree.keys())\n",
    "        ''' print search_space.keys() you will understand  \n",
    "         why we need an additional tree, '''\n",
    "        l = len(items)\n",
    "        self.prune(k, tree, search_space)\n",
    "        if l == 0: return  # Stop condition\n",
    "        for i in range(l - 1):\n",
    "            sub_search_space = {}\n",
    "            sub_tree = {}\n",
    "            a = items[i]\n",
    "            if search_space[a]['pruned']: continue\n",
    "\n",
    "            for j in range(i + 1, l):\n",
    "                b = items[j]\n",
    "                search_space[a][b] = {}\n",
    "                tree[a][b] = {}\n",
    "                # You really need to understand what am i doing here before doing work below.\n",
    "                # (Hint: draw tree and search space to draft).\n",
    "\n",
    "                # TODO:\n",
    "                # First create newset using join set\n",
    "                newset=joinset(search_space[a]['itemset'],search_space[b]['itemset'])\n",
    "                sp_newset=self.computeItemsetSupport(newset)\n",
    "                # Second add newset to search_space\n",
    "                search_space[a][b]={'itemset':list(newset),'pruned':False,'support':sp_newset}\n",
    "                sub_search_space[b]=search_space[a][b]\n",
    "                sub_tree[b]={}\n",
    "            #  Generate search_space for k+1-itemset\n",
    "            self.generateSearchSpace(k + 1, sub_tree, sub_search_space)\n",
    "\n",
    "    def runAlgorithm(self):\n",
    "        tree, search_space = self.initialize()  # generate search space for 1-itemset\n",
    "        self.generateSearchSpace(1, tree, search_space)\n",
    "\n",
    "    def miningResults(self):\n",
    "        return self.L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6tMTpwxLRjZ-"
   },
   "source": [
    "Ok, let's test on a typical dataset `chess`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "gLygYqiYRjZ-"
   },
   "outputs": [],
   "source": [
    "data, s= readData('chess.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PnxbU77YRjaF",
    "outputId": "c3b158be-6b46-4a3c-9b71-6a92d3d31ded"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: [[48], [56], [66], [34], [62], [7], [36], [60], [40], [29], [52], [58]], 2: [[48, 52], [48, 58], [56, 29], [56, 52], [56, 58], [66, 60], [66, 29], [66, 52], [66, 58], [40, 34], [34, 29], [34, 52], [34, 58], [60, 62], [40, 62], [29, 62], [52, 62], [58, 62], [60, 7], [40, 7], [29, 7], [52, 7], [58, 7], [36, 60], [40, 36], [36, 29], [36, 52], [58, 36], [40, 60], [60, 29], [60, 52], [58, 60], [40, 29], [40, 52], [40, 58], [52, 29], [58, 29], [58, 52]], 3: [[48, 58, 52], [56, 52, 29], [56, 58, 29], [56, 58, 52], [66, 60, 29], [66, 60, 52], [66, 60, 58], [66, 52, 29], [66, 58, 29], [66, 52, 58], [40, 34, 29], [40, 34, 52], [40, 34, 58], [34, 52, 29], [34, 58, 29], [34, 52, 58], [60, 29, 62], [60, 62, 52], [58, 60, 62], [40, 29, 62], [40, 52, 62], [40, 58, 62], [52, 29, 62], [58, 29, 62], [58, 52, 62], [40, 60, 7], [60, 29, 7], [60, 52, 7], [58, 60, 7], [40, 29, 7], [40, 52, 7], [40, 58, 7], [52, 29, 7], [58, 29, 7], [58, 52, 7], [40, 36, 60], [36, 29, 60], [36, 60, 52], [58, 36, 60], [40, 36, 29], [40, 36, 52], [40, 58, 36], [36, 29, 52], [58, 36, 29], [58, 36, 52], [40, 60, 29], [40, 60, 52], [40, 58, 60], [60, 29, 52], [58, 60, 29], [58, 60, 52], [40, 52, 29], [40, 58, 29], [40, 58, 52], [58, 52, 29]], 4: [[52, 56, 58, 29], [66, 52, 60, 29], [66, 58, 60, 29], [66, 52, 58, 60], [66, 52, 58, 29], [34, 52, 40, 29], [34, 40, 58, 29], [34, 52, 40, 58], [34, 52, 58, 29], [58, 60, 29, 62], [52, 58, 60, 62], [52, 40, 29, 62], [40, 58, 29, 62], [52, 40, 58, 62], [52, 58, 29, 62], [7, 40, 58, 60], [52, 7, 60, 29], [7, 58, 60, 29], [52, 7, 58, 60], [52, 7, 40, 29], [7, 40, 58, 29], [52, 7, 40, 58], [52, 7, 58, 29], [36, 40, 60, 29], [36, 52, 40, 60], [36, 40, 58, 60], [36, 52, 60, 29], [36, 58, 60, 29], [36, 52, 58, 60], [36, 52, 40, 29], [36, 40, 58, 29], [36, 52, 40, 58], [36, 52, 58, 29], [52, 40, 60, 29], [40, 58, 60, 29], [52, 40, 58, 60], [52, 58, 60, 29], [52, 40, 58, 29]], 5: [[66, 52, 58, 60, 29], [34, 40, 52, 58, 29], [40, 52, 58, 29, 62], [7, 52, 58, 60, 29], [7, 40, 52, 58, 29], [36, 40, 52, 60, 29], [36, 40, 58, 60, 29], [36, 40, 52, 58, 60], [36, 52, 58, 60, 29], [36, 40, 52, 58, 29], [40, 52, 58, 60, 29]], 6: [[36, 40, 52, 58, 60, 29]]}\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "a=TP(data=data,s=s, minSup=3000)\n",
    "print(a.miningResults())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mp0RFbw-RjaU"
   },
   "source": [
    "### Answer questions here:\n",
    "**Why don't we compute support of items while reading data?**\n",
    "- B·ªüi v√¨, th·ª© nh·∫•t l√† do c√°c b∆∞·ªõc ƒë·ªçc d·ªØ li·ªáu t·ª´ h√†m readData kh√¥ng th·ªÉ bi·∫øt tr∆∞·ªõc ƒë∆∞·ª£c s·ªë l∆∞·ª£ng transactions c√≥ trong d·ªØ li·ªáu. B·ªô d·ªØ li·ªáu ƒë∆∞·ª£c ƒë·ªçc b·∫±ng c√°ch duy·ªát qua l·∫ßn l∆∞·ª£t t·ª´ng transaction ƒë·ªÉ ƒë·ªçc t·∫•t c·∫£ item v√†o ƒë·ªëi t∆∞·ª£ng s, n·∫øu duy·ªát qua to√†n b·ªô ƒë·ªÉ bi·∫øt ƒë∆∞·ª£c s·ªë l∆∞·ª£ng transaction s·∫Ω l·∫≠p code l√†m tƒÉng th·ªùi gian kh√¥ng ƒë√°ng c√≥.\n",
    "- H∆°n n·ªØa vi·ªác t√≠nh support cho itemset s·∫Ω ƒë∆∞·ª£c l·∫∑p l·∫°i nhi·ªÅu l·∫ßn v·ªÅ sau cho c√°c L-itemsets kh√°c (v·ªõi L>1). Do ƒë√≥ vi·∫øt m·ªôt h√†m t√≠nh support trong class TP m·ªôt c√°ch ph√π h·ª£p s·∫Ω h·ªØu √≠ch cho c√°c b∆∞·ªõc sau.\n",
    "\n",
    "**why should we do sort**\n",
    "- Vi·ªác s·∫Øp x·∫øp c√°c item trong self.s theo th·ª© t·ª± tƒÉng d·∫ßn c·ªßa support count s·∫Ω gi√∫p cho vi·ªác n·∫øu x√°c ƒë·ªãnh ƒë∆∞·ª£c m·ªôt itemset l√† kh√¥ng ph·ªï bi·∫øn th√¨ n√≥ s·∫Ω c√≥ s·ªë l∆∞·ª£ng item l√† nh·ªè nh·∫•t.\n",
    "- V√≠ d·ª• ta c√≥ c√°c c·∫∑p item:support count trong self.s ƒë∆∞·ª£c x·∫øp l·ªôn x·ªôn nh∆∞ sau: {3:3, 1:1, 2:3} v·ªõi min support count l√† 2 th√¨ theo thu·∫≠t to√°n Tree Projection ƒë∆∞·ª£c c√†i ƒë·∫∑t b√™n tr√™n, itemset [3] th·ªèa l√† t·∫≠p ph·ªï bi·∫øn n√™n s·∫Ω ti·∫øp t·ª•c t·∫°o kh√¥ng gian t√¨m ki·∫øm cho tr∆∞·ªùng h·ª£p k=2 b·∫Øt ƒë·∫ßu t·ª´ 3 v√† [3,1] v√† [3,2] s·∫Ω ƒë∆∞·ª£c th√™m v√†o search space r·ªìi m·ªõi th·ª±c hi·ªán t·ªâa. Trong khi c√≥ th·ªÉ b·ªè qua t·∫•t c·∫£ l·∫ßn duy·ªát c√°c itemset c√≥ ch·ª©a item 1 n·∫øu x√©t item 1 ƒë·∫ßu ti√™n ngay t·ª´ ƒë·∫ßu.\n",
    "\n",
    "**study about python set and its advantages ?**\n",
    "- Set trong Python l√† ki·ªÉu d·ªØ li·ªáu t·∫≠p h·ª£p kh√¥ng c√≥ th·ª© t·ª±, c√≥ th·ªÉ thay ƒë·ªïi v√† kh√¥ng c√≥ ph·∫ßn t·ª≠ tr√πng l·∫∑p. Set ƒë∆∞·ª£c k√Ω hi·ªáu b·ªüi c·∫∑p d·∫•u ngo·∫∑c nh·ªçn {}. C√°c ph·∫ßn t·ª≠ c·ªßa set s·∫Ω ƒë∆∞·ª£c ƒë·∫∑t trong c·∫∑p ngo·∫∑c nh·ªçn.\n",
    "- Set kh√¥ng c√≥ t√≠nh th·ª© t·ª± do vi·ªác c√†i ƒë·∫∑t set l√† b·∫±ng b·∫£ng bƒÉm, ch√∫ng ta s·∫Ω kh√¥ng bi·∫øt th·ª© t·ª± l∆∞u c√°c ph·∫ßn t·ª≠ v√†o set nh∆∞ th·∫ø n√†o m√† t√πy thu·ªôc v√†o c√°ch bƒÉm. Do vi·ªác c√†i ƒë·∫∑t b√†ng b·∫£ng bƒÉm n√™n set c√≥ c√°c ∆∞u ƒëi·ªÉm ch√≠nh nh∆∞ sau:\n",
    "  + ƒêi·ªÅu n√†y cho ph√©p c√°c ph√©p to√°n tr√™n set ƒë∆∞·ª£c th·ª±c hi·ªán v·ªõi ƒë·ªô ph·ª©c t·∫°p th·ªùi gian trung b√¨nh l√† O(1). Khi ki·ªÉm tra xem m·ªôt ph·∫ßn t·ª≠ c√≥ trong set hay kh√¥ng Python ch·ªâ c·∫ßn t√≠nh to√°n m√£ bƒÉm c·ªßa ph·∫ßn t·ª≠ v√† ki·ªÉm tra xem ph·∫ßn t·ª≠ c√≥ trong b·∫£ng bƒÉm hay kh√¥ng.\n",
    "  + Set kh√¥ng ch·ª©a c√°c ph·∫ßn t·ª≠ tr√πng l·∫∑p, n√™n r·∫•t d·ªÖ d√†ng ƒë·ªÉ th·ª±c hi·ªán ph√©p h·ªôi.\n",
    "  + Set h·ªó tr·ª£ m·∫°nh v·ªÅ c√°c ph√©p to√°n li√™n quan ƒë·∫øn t·∫≠p h·ª£p nh∆∞ giao, h·ª£p, hi·ªáu, .... Do ƒë√≥ vi·ªác ki·ªÉm tra ph·∫ßn t·ª≠ c√≥ trong set tr·ªü n√™n r·∫•t d·ªÖ d√†ng.\n",
    "- V·∫≠y l·ª£i √≠ch c·ªßa vi·ªác d√πng set trong khi c√†i ƒë·∫∑t thu·∫≠t to√°n Tree Projection:\n",
    "  + Th·ª±c hi·ªán vi·ªác h·ª£p(join) 2 itemset trong h√†m joinset s·∫Ω lo·∫°i b·ªè ƒë∆∞·ª£c vi·ªác tr√πng l·∫∑p ph·∫ßn t·ª≠ ngay l·∫≠p t·ª©c m√† kh√¥ng c·∫ßn code qu√° ph·ª©c t·∫°p.\n",
    "  + Khi t√≠nh support cho c√°c L-itemsets (L>1) trong h√†m computeItemsetSupport, ta ki·ªÉm tra c√°c item c·ªßa m·ªôt itemset c√≥ c√πng xu·∫•t hi·ªán trong m·ªôt transaction hay kh√¥ng r·∫•t d·ªÖ d√†ng qua ph√©p to√°n giao (intersection) tr√™n set.\n",
    "  + Khi b·ªô d·ªØ li·ªáu r·∫•t l·ªõn th√¨ l√†m vi·ªác tr√™n set gi√∫p tƒÉng t·ªëc ƒë·ªô h∆°n r·∫•t nhi·ªÅu so v·ªõi tr√™n list.\n",
    "\n",
    "**After finish implementing the algorithm tell me why should you use this? Instead of delete item directly from search_space and tree.**\n",
    "- Vi·ªác d√πng pruned = True/False ƒë·ªÉ cho bi·∫øt itemset c√≥ l√† ph·ªï bi·∫øn hay kh√¥ng m√† kh√¥ng x√≥a tr·ª±c ti·∫øp trong search_space v√† tree l√† do thu·∫≠t to√°n ƒë∆∞·ª£c c√†i ƒë·∫∑t t√¨m ki·∫øm c√°c itemset ph·ªï bi·∫øn m·ªôt c√°ch ƒë·ªá qui b·∫Øt ƒë·∫ßu t·ª´ kh√¥ng gian t√¨m ki·∫øm cho k=1 v√† tƒÉng d·∫ßn l√™n k=2, 3, 4, ....\n",
    "- V√† ·ªü kh√¥ng gian t√¨m ki·∫øm cho k+1 th√¨ tree v√† search_space s·∫Ω l·∫°i l√† sub_tree v√† sub_searchspace v·ªõi c√°c b·ªô key-value ho√†n to√†n m·ªõi ƒë∆∞·ª£c k·∫ø th·ª´a t·ª´ vi·ªác k·∫øt h·ª£p c√°c itemset ·ªü kh√¥ng gian k. Do ƒë√≥ n·∫øu c√≥ x√≥a tr·ª±c ti·∫øp th√¨ cu·ªëi c√πng n·∫øu t·∫•t c·∫£ 1-itemset ban ƒë·∫ßu ƒë·ªÅu l√† t·∫≠p ph·ªï bi·∫øn th√¨ search_space v√† tree v·∫´n ch·ª©a ƒë·∫ßy ƒë·ªß c√°c nhanh v√† l√∫c n√†y kh√¥ng c√≥ c√°ch ƒë·ªÉ nh·∫≠n bi·∫øt ƒë√¢u l√† t·∫≠p kh√¥ng ph·ªï bi·∫øn v√† nh√°nh n√™n b·ªã t·ªâa.\n",
    "\n",
    "**Apriori algorithm and Tree Projection, tell me the differences of two algorithms.**\n",
    "\n",
    "**1. V·ªÅ c·∫•u tr√∫c d·ªØ li·ªáu:**\n",
    "  - Apriori d√πng c·∫•u tr√∫c d·∫°ng t·∫≠p h·ª£p (nh∆∞ list, b·∫£ng) ƒë·ªÉ l∆∞u c√°c t·∫≠p ·ª©ng vi√™n C v√† c√°c t·∫≠p ph·ªï bi·∫øn L.\n",
    "  - Tree Projection s·∫Ω l∆∞u c√°c itemset trong c√°c node c·ªßa c·∫•u tr√∫c c√¢y.\n",
    "**2. C√°ch t√¨m t·∫≠p ph·ªï bi·∫øn:**\n",
    "  - Apriori s·∫Ω t·∫°o t·∫≠p ${C}_{k+1}$ b·∫±ng c√°ch k·∫øt h·ª£p t·∫•t c·∫£ c√°c itemset trong ${L}_{k}$ l·∫°i v·ªõi nhau. R·ªìi sau ƒë√≥ duy·ªát l·∫ßn l∆∞·ª£t qua h·∫øt ${C}_{k+1}$ ƒë·ªÉ t√¨m nh·ªØng itemset th·ªèa min support v√† th√™m v√†o ${L}_{k+1}$.\n",
    "  - Tree Projection s·∫Ω l∆∞u ·ªü m·ª©c 1 c·ªßa c√¢y c√°c 1-itemset ·ª©ng vi√™n v√† sau ƒë√≥ lo·∫°i ngay l·∫≠p t·ª©c c√°c itemset ·ª©ng vi√™n kh√¥ng l√† t·∫≠p ph·ªï bi·∫øn, sau ƒë√≥ t·ª´ c√°c 1-itemset ph·ªï bi·∫øn c√≤n l·∫°i t·∫°o ti·∫øp **theo chi·ªÅu s√¢u** c√°c L-itemset ·ª©ng vi√™n (L>1) ·ªü c√°c m·ª©c cao h∆°n c·ªßa c√¢y, v√† v·∫´n ti·∫øn h√†nh lo·∫°i ngay nh·ªØng itemset n√†o kh√¥ng ph·ªï bi·∫øn.\n",
    "  - V√≠ d·ª• ta c√≥ c√°c item ban ƒë·∫ßu c·ªßa database l√† 1, 2, 3, 4. **Gi·∫£ s·ª≠:** itemset [1] s·∫Ω kh√¥ng th·ªèa min support, c√°c itemset [2], [3], [4] v√† t·∫•t c·∫£ c√°c itemset kh√°c ƒë∆∞·ª£c t·∫°o ra sau n√†y ƒë·ªÅu s·∫Ω th·ªèa min support, ta c√≥ h√¨nh ·∫£nh nh∆∞ sau:\n",
    "  ![img](https://res.cloudinary.com/vtphong/image/upload/v1681221934/data-mining/image1.png)\n",
    "  - ƒê·∫ßu ti√™n l√† x√≥a itemset [1], sau ƒë√≥ t·∫°o c√°c itemset kh√°c theo chi·ªÅu c√°c m≈©i t√™n m√†u ƒë·ªè v√† cu·ªëi c√πng m·ªõi ƒë·∫øn t·∫°o itemset [3, 4].\n",
    "**3. V·ªÅ hi·ªáu su·∫•t:**\n",
    "  - Thu·∫≠t to√°n Tree Projection th∆∞·ªùng cho hi·ªáu su·∫•t t·ªët h∆°n v·ªÅ m·∫∑t t·ªëc ƒë·ªô so v·ªõi thu·∫≠t to√°n Apriori, ƒë·∫∑c bi·ªát l√† khi x·ª≠ l√Ω c√°c t·∫≠p d·ªØ li·ªáu l·ªõn v√† c√°c t·∫≠p ph·ªï bi·∫øn c√≥ k√≠ch th∆∞·ªõc l·ªõn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NnVm8wYIRjaV"
   },
   "source": [
    "# 3. Churn analysis\n",
    "\n",
    "In this section, you will use frequent itemset mining technique to analyze `churn` dataset (for any purposes). \n",
    "\n",
    "*Remember this dataset is not represented as a transactional database, first thing that you have to do is transforming it into a flat file.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tr∆∞·ªõc ti√™n chuy·ªÉn file 'churn.txt' sang flat file v·ªõi ƒë·ªãnh d·∫°ng l√† txt b·∫±ng h√†m convertDataset t·ª± ƒë·ªãnh nghƒ©a sau ƒë√¢y.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**M√¥ t·∫£ √Ω t∆∞·ªüng t·∫°o data:**\n",
    "- D√≤ng ƒë·∫ßu trong file churn ch·ª©a t√™n thu·ªôc t√≠nh, c√°c d√≤ng sau ch·ª©a t·ª´ng gi√° tr·ªã cho m·ªói thu·ªôc t√≠nh c·ªßa m·ªói kh√°ch h√†ng.\n",
    "- Do ƒë√≥ ta c√≥ th·ªÉ t·∫°o data c√≥ d·∫°ng nh∆∞ sau:\n",
    "  + V√≠ d·ª• m·ªói h√†ng c·ªßa file ch·ª©a data ƒë√£ chuy·ªÉn ƒë·ªïi s·∫Ω t∆∞∆°ng ·ª©ng l√† th√¥ng tin c·ªßa m·ªói kh√°ch h√†ng trong file churn.txt. Khi ƒë√≥ file data ƒë√£ chuy·ªÉn ƒë·ªïi s·∫Ω c√≥ d·∫°ng:\n",
    "  \n",
    "<thu·ªôc t√≠nh 1>:<gi√° tr·ªã 1_1>;<thu·ªôc t√≠nh 2>:<gi√° tr·ªã 1_2>;...;<thu·ªôc t√≠nh n>:<gi√° tr·ªã 1_n>\n",
    "  \n",
    "<thu·ªôc t√≠nh 1>:<gi√° tr·ªã 2_1>;<thu·ªôc t√≠nh 2>:<gi√° tr·ªã 2_2>;...;<thu·ªôc t√≠nh n>:<gi√° tr·ªã 2_n>\n",
    "  \n",
    "...\n",
    "  \n",
    "<thu·ªôc t√≠nh 1>:<gi√° tr·ªã m_1>;<thu·ªôc t√≠nh 2>;<gi√° tr·ªã m_2>;...;<thu·ªôc t√≠nh n>:<gi√° tr·ªã m_n>\n",
    "  \n",
    "  + **V·ªõi n l√† s·ªë thu·ªôc t√≠nh ban ƒë·∫ßu trong file churn.txt, m l√† s·ªë kh√°ch h√†ng ban ƒë·∫ßu trong file churn.txt**.\n",
    "  + **ƒê·∫∑t t√™n l√† 'data.txt'**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertDataset(path):\n",
    "    columns_name=[\"State\",\"Account Length\",\"Area Code\",\"Phone\",\"Int'l Plan\",\"VMail Plan\",\"VMail Message\",\n",
    "                  \"Day Mins\",\"Day Calls\",\"Day Charge\",\"Eve Mins\",\"Eve Calls\",\"Eve Charge\",\"Night Mins\",\n",
    "                  \"Night Calls\",\"Night Charge\",\"Intl Mins\",\"Intl Calls\",\"Intl Charge\",\"CustServ Calls\",\"Churn?\"]\n",
    "    f = open(path, 'r')\n",
    "    writer = open('data.txt','w')\n",
    "    temp=f.readline() #lo·∫°i b·ªè d√≤ng ƒë·∫ßu l√† c√°c thu·ªôc t√≠nh\n",
    "    for line in f:\n",
    "        data = line.split(',')\n",
    "        data[-1]=data[-1].replace('.','')\n",
    "        for i in range(len(columns_name)):\n",
    "            data[i]=columns_name[i]+':'+data[i]\n",
    "        row=';'.join(data)\n",
    "        writer.write(row)\n",
    "    f.close()\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "convertDataset('churn.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**M√¥ t·∫£ √Ω t∆∞·ªüng ph√¢n t√≠ch d·ªØ li·ªáu churn:**\n",
    "- Churn l√† d·ªØ li·ªáu kh√°ch h√†ng r·ªùi b·ªè d·ªãch v·ª•. V·ªõi c√°c th√¥ng tin li√™n quan th√¨ kh√°ch h√†ng c√≥ r·ªùi b·ªè d·ªãch v·ª• hay kh√¥ng?\n",
    "- V·∫≠y ta c√≥ th·ªÉ nghƒ© ƒë·∫øn vi·ªác t√¨m c√°c t·∫≠p ph·ªï bi·∫øn c√≥ ch·ª©a y·∫øu t·ªë churn, sau ƒë√≥ t√≠m ra c√°c lu·∫≠t k·∫øt h·ª£p m√† y·∫øu t·ªë churn n·∫±m ·ªü v·∫ø ph·∫£i th·ªèa m·ªôt min confidence n√†o ƒë√≥, t·∫•t nhi√™n nh·ªØng y·∫øu t·ªë ·ªü v·∫ø tr√°i c·ªßa lu·∫≠t s·∫Ω l√† nh·ªØng y·∫øu t·ªë ·∫£nh h∆∞·ªüng ƒë·∫øn vi·ªác kh√°ch h√†ng c√≥ r·ªùi b·ªè d·ªãch v·ª• hay kh√¥ng."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**T·∫≠n d·ª•ng l·∫°i h√†m readData, v√† l·ªõp TP ƒë·ªÉ t√¨m t·∫≠p ph·ªï bi·∫øn.** Nh∆∞ng c·∫ßn ƒë·ªãnh nghƒ©a l·∫°i m·ªôt ch√∫t h√†m readDataset ƒë·ªÉ c√≥ th·ªÉ l∆∞u c√°c itemset ki·ªÉu string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readDataset(path):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    --------------------------\n",
    "        path: path of database D.\n",
    "         \n",
    "    --------------------------\n",
    "    Returns\n",
    "        data: a dictionary for representing database D\n",
    "                 - keys: transaction tids\n",
    "                 - values: itemsets.\n",
    "        s: support of distict items in D.\n",
    "    \"\"\"\n",
    "    data={}\n",
    "    s=defaultdict(lambda: 0) # Initialize a dictionary for storing support of items in I.  \n",
    "    with open(path,'rt') as f:\n",
    "        tid=1;\n",
    "        for line in f:\n",
    "            line=line.strip()\n",
    "            itemset=set(line.split(';')) \n",
    "            for item in itemset:  \n",
    "                s[item]+=1    \n",
    "            data[tid]= itemset\n",
    "            tid+=1\n",
    "    \n",
    "    return data, s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChurnAnalysis:\n",
    "    def __init__(self, data=None, s=None, L=None, attribute=None, minConf=None):\n",
    "        self.data=data\n",
    "        self.s=s\n",
    "        self.L=L\n",
    "        self.attribute=attribute\n",
    "        self.minConf=minConf\n",
    "        self.filtered_L={}\n",
    "        self.AscRules=[]\n",
    "        \n",
    "    def joinset(a, b):\n",
    "        ret=list(set(a) | set(b))\n",
    "        return ret\n",
    "    \n",
    "    def filterFrequentItemsets(self):\n",
    "        L2={}\n",
    "        for k in self.L.keys():\n",
    "            if k==1:\n",
    "                continue\n",
    "            L2[k]=[]\n",
    "            for i in range(len(self.L[k])):\n",
    "                L2[k].append([])\n",
    "                check_exist=False\n",
    "                for item in self.L[k][i]:\n",
    "                    if self.attribute in item:\n",
    "                        check_exist=True\n",
    "                if check_exist==True:\n",
    "                    for item in self.L[k][i]:\n",
    "                        L2[k][i].append(item)\n",
    "            for i in L2[k]:\n",
    "                if len(i)==0:\n",
    "                    L2[k].remove(i)\n",
    "            if len(L2[k])==0:\n",
    "                del L2[k]\n",
    "        return L2\n",
    "    \n",
    "    def computeItemsetSupport(self,itemset):\n",
    "        support=0\n",
    "        for i in self.data.keys():\n",
    "            if len(set(itemset)) == len(set(itemset).intersection(self.data[i])):\n",
    "                support+=1\n",
    "        return support/len(self.data.keys())\n",
    "    \n",
    "    def computeRuleSupport(self, leftSide, rightSide):\n",
    "        return self.computeItemsetSupport(joinset(leftSide, rightSide))\n",
    "    \n",
    "    def computeRuleConfidence(self, leftSide, rightSide):\n",
    "        return self.computeItemsetSupport(joinset(leftSide, rightSide))/self.computeItemsetSupport(leftSide)\n",
    "    \n",
    "    def generateARule(self,itemset):\n",
    "        itemset_copy=itemset.copy()\n",
    "        leftSide, rightSide=[], []\n",
    "        rule={}\n",
    "        for i in itemset:\n",
    "            if self.attribute in i:\n",
    "                rightSide.append(i)\n",
    "                itemset_copy.remove(i)\n",
    "                leftSide=itemset_copy\n",
    "                break\n",
    "        rule[tuple(leftSide)]={}\n",
    "        rule[tuple(leftSide)]['result']=rightSide\n",
    "        rule[tuple(leftSide)]['support']=self.computeRuleSupport(leftSide, rightSide)\n",
    "        rule[tuple(leftSide)]['confidence']=self.computeRuleConfidence(leftSide, rightSide)\n",
    "        return rule\n",
    "    \n",
    "    def generateAllRules(self):\n",
    "        self.filtered_L=self.filterFrequentItemsets()\n",
    "        for k in self.filtered_L.keys():\n",
    "            for i in self.filtered_L[k]:\n",
    "                rule=self.generateARule(i)\n",
    "                if list(rule.values())[0]['confidence']>=self.minConf:\n",
    "                    self.AscRules.append(rule)\n",
    "        return self.AscRules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2, s2=readDataset('data.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "minSup=int(0.5*len(list(data2.keys()))) #minSup b·∫±ng 50% s·ªë l∆∞·ª£ng transactions\n",
    "frequentItemsets=TP(data=data2,s=s2, minSup=minSup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules=ChurnAnalysis(data=data2,s=s2,L=frequentItemsets.miningResults(),attribute='Churn?',minConf=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{('VMail Plan:no',): {'result': ['Churn?:False'],\n",
       "   'support': 0.6024602460246025,\n",
       "   'confidence': 0.8328494400663625}},\n",
       " {('VMail Message:0',): {'result': ['Churn?:False'],\n",
       "   'support': 0.6024602460246025,\n",
       "   'confidence': 0.8328494400663625}},\n",
       " {(\"Int'l Plan:no\",): {'result': ['Churn?:False'],\n",
       "   'support': 0.7992799279927992,\n",
       "   'confidence': 0.8850498338870432}},\n",
       " {('VMail Plan:no', 'VMail Message:0'): {'result': ['Churn?:False'],\n",
       "   'support': 0.6024602460246025,\n",
       "   'confidence': 0.8328494400663625}},\n",
       " {('VMail Plan:no', \"Int'l Plan:no\"): {'result': ['Churn?:False'],\n",
       "   'support': 0.5634563456345635,\n",
       "   'confidence': 0.861467889908257}},\n",
       " {(\"Int'l Plan:no\", 'VMail Message:0'): {'result': ['Churn?:False'],\n",
       "   'support': 0.5634563456345635,\n",
       "   'confidence': 0.861467889908257}},\n",
       " {('VMail Plan:no',\n",
       "   \"Int'l Plan:no\",\n",
       "   'VMail Message:0'): {'result': ['Churn?:False'], 'support': 0.5634563456345635, 'confidence': 0.861467889908257}}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rules.generateAllRules()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Em t·∫°o m·ªôt l·ªõp t√™n l√† ChurnAnalysis ƒë·ªÉ ph√¢n t√≠ch t·∫≠p churn nh∆∞ sau:\n",
    "  + Ph∆∞∆°ng th·ª©c filterFrequentItemsets s·∫Ω l·ªçc ra c√°c t·∫≠p L-itemsets (L>=2) l√† t·∫≠p h·ª£p nh·ªØng t·∫≠p ph·ªï bi·∫øn ch·ª©a y·∫øu t·ªë churn nh∆∞ng c√≥ t·ª´ 2 ph·∫ßn t·ª≠ tr·ªü l√™n (do ƒë·ªÉ t·∫°o lu·∫≠t t·ª´ itemset ph·∫£i c√≥ t·ª´ 2 ph·∫ßn t·ª≠ tr·ªü l√™n trong itemset).\n",
    "  + Ph∆∞∆°ng th·ª©c computeRuleConfidence t√≠nh confidence cho lu·∫≠t.\n",
    "  + Ph∆∞∆°ng th·ª©c generateAllRules d√πng ƒë·ªÉ sinh t·∫•t c·∫£ c√°c lu·∫≠t m√† v·∫ø ph·∫£i l√† y·∫øu t·ªë churn th·ªèa min confidence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ƒê·ªÉ kh√¥ng m·∫•t t√≠nh t·ªïng qu√°t cho l·ªõp v√† c√°c ph∆∞∆°ng th·ª©c, c√≥ th·ªÉ ƒë·ªïi y·∫øu t·ªë churn th√†nh y·∫øu t·ªë kh√°c v√† min confidence l√† m·ªôt gi√° tr·ªã kh√°c ƒë·ªÉ truy·ªÅn v√†o l·ªõp v√† sinh c√°c lu·∫≠t li√™n quan.\n",
    "- C√≥ th·ªÉ th·∫•y list tr√™n ch·ª©a c√°c dictionary v·ªõi m·ªói dictionary l√† m·ªôt lu·∫≠t:\n",
    "  + Key s·∫Ω l√† v·∫ø tr√°i c·ªßa lu·∫≠t.\n",
    "  + 'result' s·∫Ω l√† v·∫ø ph·∫£i c·ªßa lu·∫≠t.\n",
    "  + support l√† support c·ªßa lu·∫≠t.\n",
    "  + confidence l√† confidence c·ªßa lu·∫≠t."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- C√≥ th·ªÉ th·∫•y trong dataset n√†y v·ªõi min support b·∫±ng 50% th√¨ kh√¥ng c√≥ t·∫≠p ph·ªï bi·∫øn n√†o ch·ª©a churn=True (kh√°ch h√†ng r·ªùi b·ªè d·ªãch v·ª•).\n",
    "- C√≥ nhi·ªÅu t·∫≠p ph·ªï bi·∫øn ch·ª©a churn=False, v·∫≠y ta s·∫Ω ph√¢n t√≠ch theo h∆∞·ªõng k·∫øt h·ª£p nh·ªØng y·∫øu t·ªë n√†o ƒë·ªÉ tƒÉng kh·∫£ nƒÉng gi·ªØ l·∫°i kh√°ch h√†ng. V√† ƒë·ªÉ l√†m ƒë∆∞·ª£c ƒëi·ªÅu n√†y th√¨ nh·ªØng lu·∫≠t ·ªü tr√™n l√† s·ª± g·ª£i √Ω t·ªët ƒë·ªÉ tham kh·∫£o.\n",
    "- **ƒê·ªÉ xem t·∫•t c·∫£ c√°c t·∫≠p ph·ªï bi·∫øn khi ch∆∞a l·ªçc theo thu·ªôc t√≠nh ƒë∆∞·ª£c ch·ªçn, c√≥ th·ªÉ d√πng thu·ªôc t√≠nh .L**.\n",
    "- **ƒê·ªÉ xem t·∫•t c·∫£ c√°c t·∫≠p ph·ªï bi·∫øn khi ƒë√£ l·ªçc theo thu·ªôc t√≠nh ƒë∆∞·ª£c ch·ªçn, c√≥ th·ªÉ d√πng thu·ªôc t√≠nh .filtered_L**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T·∫•t c·∫£ c√°c t·∫≠p ph·ªï bi·∫øn v·ªõi min support ƒë√£ cho:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{1: [['VMail Plan:no'],\n",
       "  ['VMail Message:0'],\n",
       "  ['Churn?:False'],\n",
       "  [\"Int'l Plan:no\"]],\n",
       " 2: [['VMail Plan:no', 'VMail Message:0'],\n",
       "  ['VMail Plan:no', 'Churn?:False'],\n",
       "  ['VMail Plan:no', \"Int'l Plan:no\"],\n",
       "  ['Churn?:False', 'VMail Message:0'],\n",
       "  [\"Int'l Plan:no\", 'VMail Message:0'],\n",
       "  ['Churn?:False', \"Int'l Plan:no\"]],\n",
       " 3: [['VMail Plan:no', 'Churn?:False', 'VMail Message:0'],\n",
       "  ['VMail Plan:no', \"Int'l Plan:no\", 'VMail Message:0'],\n",
       "  ['VMail Plan:no', 'Churn?:False', \"Int'l Plan:no\"],\n",
       "  ['Churn?:False', \"Int'l Plan:no\", 'VMail Message:0']],\n",
       " 4: [['Churn?:False', 'VMail Plan:no', \"Int'l Plan:no\", 'VMail Message:0']]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('T·∫•t c·∫£ c√°c t·∫≠p ph·ªï bi·∫øn v·ªõi min support ƒë√£ cho:\\n')\n",
    "rules.L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**N·∫øu tr√™n ph∆∞∆°ng di·ªán l√† ch·ªß d·ªãch v·ª•, ƒë·ªÉ ch·∫Øc ch·∫Øn l√† kh√¥ng c√≥ y·∫øu t·ªë ·∫£nh h∆∞·ªüng n√†o l√†m cho churn=true ƒë√°ng lo ng·∫°i x·∫£y ra, em s·∫Ω xem x√©t t·∫≠p d·ªØ li·ªáu v·ªõi m·ªôt min support r·∫•t th·∫•p h∆°n (20% c≈©ng ƒë√£ ƒë·ªß l√†m em lo l·∫Øng üòÅ)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "minSup2=int(0.2*len(list(data2.keys()))) #minSup b·∫±ng 20% s·ªë l∆∞·ª£ng transactions\n",
    "frequentItemsets2=TP(data=data2,s=s2, minSup=minSup2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules2=ChurnAnalysis(data=data2,s=s2,L=frequentItemsets2.miningResults(),attribute='Churn?',minConf=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{('CustServ Calls:2',): {'result': ['Churn?:False'],\n",
       "   'support': 0.20162016201620162,\n",
       "   'confidence': 0.8853754940711462}},\n",
       " {('Area Code:408',): {'result': ['Churn?:False'],\n",
       "   'support': 0.2148214821482148,\n",
       "   'confidence': 0.8544152744630071}},\n",
       " {('Area Code:510',): {'result': ['Churn?:False'],\n",
       "   'support': 0.2145214521452145,\n",
       "   'confidence': 0.8511904761904762}},\n",
       " {('VMail Plan:yes',): {'result': ['Churn?:False'],\n",
       "   'support': 0.2526252625262526,\n",
       "   'confidence': 0.9132321041214749}},\n",
       " {('CustServ Calls:1',): {'result': ['Churn?:False'],\n",
       "   'support': 0.3177317731773177,\n",
       "   'confidence': 0.8966977138018628}},\n",
       " {('Area Code:415',): {'result': ['Churn?:False'],\n",
       "   'support': 0.42574257425742573,\n",
       "   'confidence': 0.8574018126888218}},\n",
       " {(): {'result': [], 'support': 1.0, 'confidence': 1.0}},\n",
       " {('VMail Plan:no',): {'result': ['Churn?:False'],\n",
       "   'support': 0.6024602460246025,\n",
       "   'confidence': 0.8328494400663625}},\n",
       " {(): {'result': [], 'support': 1.0, 'confidence': 1.0}},\n",
       " {('VMail Message:0',): {'result': ['Churn?:False'],\n",
       "   'support': 0.6024602460246025,\n",
       "   'confidence': 0.8328494400663625}},\n",
       " {(): {'result': [], 'support': 1.0, 'confidence': 1.0}},\n",
       " {(\"Int'l Plan:no\",): {'result': ['Churn?:False'],\n",
       "   'support': 0.7992799279927992,\n",
       "   'confidence': 0.8850498338870432}},\n",
       " {(\"Int'l Plan:no\", 'Area Code:408'): {'result': ['Churn?:False'],\n",
       "   'support': 0.20312031203120312,\n",
       "   'confidence': 0.8826597131681878}},\n",
       " {('VMail Plan:yes', \"Int'l Plan:no\"): {'result': ['Churn?:False'],\n",
       "   'support': 0.23582358235823583,\n",
       "   'confidence': 0.946987951807229}},\n",
       " {('VMail Plan:no', 'CustServ Calls:1'): {'result': ['Churn?:False'],\n",
       "   'support': 0.21992199219921993,\n",
       "   'confidence': 0.8757467144563919}},\n",
       " {('CustServ Calls:1', 'VMail Message:0'): {'result': ['Churn?:False'],\n",
       "   'support': 0.21992199219921993,\n",
       "   'confidence': 0.8757467144563919}},\n",
       " {(\"Int'l Plan:no\", 'CustServ Calls:1'): {'result': ['Churn?:False'],\n",
       "   'support': 0.29612961296129614,\n",
       "   'confidence': 0.9232927970065482}},\n",
       " {('VMail Plan:no', 'Area Code:415'): {'result': ['Churn?:False'],\n",
       "   'support': 0.2946294629462946,\n",
       "   'confidence': 0.8293918918918919}},\n",
       " {('Area Code:415', 'VMail Message:0'): {'result': ['Churn?:False'],\n",
       "   'support': 0.2946294629462946,\n",
       "   'confidence': 0.8293918918918919}},\n",
       " {('Area Code:415', \"Int'l Plan:no\"): {'result': ['Churn?:False'],\n",
       "   'support': 0.39933993399339934,\n",
       "   'confidence': 0.8843853820598008}},\n",
       " {('VMail Plan:no', 'VMail Message:0'): {'result': ['Churn?:False'],\n",
       "   'support': 0.6024602460246025,\n",
       "   'confidence': 0.8328494400663625}},\n",
       " {('VMail Plan:no', \"Int'l Plan:no\"): {'result': ['Churn?:False'],\n",
       "   'support': 0.5634563456345635,\n",
       "   'confidence': 0.861467889908257}},\n",
       " {(\"Int'l Plan:no\", 'VMail Message:0'): {'result': ['Churn?:False'],\n",
       "   'support': 0.5634563456345635,\n",
       "   'confidence': 0.861467889908257}},\n",
       " {('VMail Plan:no',\n",
       "   'CustServ Calls:1',\n",
       "   'VMail Message:0'): {'result': ['Churn?:False'], 'support': 0.21992199219921993, 'confidence': 0.8757467144563919}},\n",
       " {('VMail Plan:no',\n",
       "   \"Int'l Plan:no\",\n",
       "   'CustServ Calls:1'): {'result': ['Churn?:False'], 'support': 0.20522052205220523, 'confidence': 0.9011857707509882}},\n",
       " {(\"Int'l Plan:no\",\n",
       "   'CustServ Calls:1',\n",
       "   'VMail Message:0'): {'result': ['Churn?:False'], 'support': 0.20522052205220523, 'confidence': 0.9011857707509882}},\n",
       " {('Area Code:415',\n",
       "   'VMail Plan:no',\n",
       "   'VMail Message:0'): {'result': ['Churn?:False'], 'support': 0.2946294629462946, 'confidence': 0.8293918918918919}},\n",
       " {('Area Code:415',\n",
       "   'VMail Plan:no',\n",
       "   \"Int'l Plan:no\"): {'result': ['Churn?:False'], 'support': 0.27782778277827785, 'confidence': 0.8558225508317931}},\n",
       " {('Area Code:415',\n",
       "   \"Int'l Plan:no\",\n",
       "   'VMail Message:0'): {'result': ['Churn?:False'], 'support': 0.27782778277827785, 'confidence': 0.8558225508317931}},\n",
       " {('VMail Plan:no',\n",
       "   \"Int'l Plan:no\",\n",
       "   'VMail Message:0'): {'result': ['Churn?:False'], 'support': 0.5634563456345635, 'confidence': 0.861467889908257}},\n",
       " {('VMail Plan:no',\n",
       "   \"Int'l Plan:no\",\n",
       "   'CustServ Calls:1',\n",
       "   'VMail Message:0'): {'result': ['Churn?:False'], 'support': 0.20522052205220523, 'confidence': 0.9011857707509882}},\n",
       " {('Area Code:415',\n",
       "   'VMail Plan:no',\n",
       "   \"Int'l Plan:no\",\n",
       "   'VMail Message:0'): {'result': ['Churn?:False'], 'support': 0.27782778277827785, 'confidence': 0.8558225508317931}}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rules2.generateAllRules()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**V·∫´n kh√¥ng c√≥ y·∫øu t·ªë n√†o l√†m cho churn = True x·∫£y ra m√† l√†m cho y·∫øu t·ªë n√†y th√†nh ph·ªï bi·∫øn.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-FzxGs7RRjaX"
   },
   "source": [
    "# 4 References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "doYH4biqR_N7"
   },
   "source": [
    "Feel free to send questions to my email address: nnduc@fit.hcmus.edu.vn\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of Lab01 - Frequent itemset mining.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
